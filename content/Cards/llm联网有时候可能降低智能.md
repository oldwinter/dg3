---
{"publish":true,"permalink":"/Cards/llm联网有时候可能降低智能.md","created":"2025-07-06","modified":"2025-07-11","published":"2025-07-29T23:04:06.655+08:00","cssclasses":""}
---


比如 Perplexity 就显得很呆，它倾向于直接去搜答案，而不是自己推理。

[[Cards/llm使用rag或memory可能降低智能]]
明确判断自己的问题，如果不是实时性很强的，其实不联网反而能获得高质量答案。因为模型预训练使用的资料，那可是人工精挑细选的，比现在推理阶段引用网上临时搜的可能都不一定靠谱的材料，要高到不知道哪里去了。
